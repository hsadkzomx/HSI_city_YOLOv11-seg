{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s6DR1ZN4nyn"
      },
      "source": [
        "# Training Ultralytics YOLOv11 Object Detection on Google Colab\n",
        "\n",
        "This notebook shows how to train Ultralytics YOLOv11 Object Detector using a custom dataset.\n",
        "\n",
        "This is done using the Google Colab infrastructure, which provides us some key features like:\n",
        "\n",
        "- ability to run processes on GPU, essential to be able to train computer vision models.\n",
        "\n",
        "- storage in Google Drive, where our data will be stored, both the dataset and the checkpoint of the trained model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtyXtQnoKT_H"
      },
      "source": [
        "# 1. Installing Ultralytics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eNSTU7lE5Eha"
      },
      "outputs": [],
      "source": [
        "# Install ultralytics package.\n",
        "\n",
        "!pip install -qq ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16dCMaH68tmx",
        "outputId": "7dc77a0a-4b8f-4941-f09d-913661dd5f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.3.80\n"
          ]
        }
      ],
      "source": [
        "# Check that the package has been installed\n",
        "import ultralytics\n",
        "\n",
        "print(ultralytics.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When the package gets installed we can run the yolo cli command.\n",
        "# the yolo settings shows us how is the package configured, and some\n",
        "# important directories paths, like:\n",
        "#Â - datasets_dir: where the datasets are expected to be stored, and\n",
        "# - runs_dir: where the processes are going to store its results\n",
        "#             (like the resulting training files)\n",
        "\n",
        "!yolo settings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYvVYzgehy8F",
        "outputId": "035228a2-5863-4384-ab01-982aab46eae5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSONDict(\"/root/.config/Ultralytics/settings.json\"):\n",
            "{\n",
            "  \"settings_version\": \"0.0.6\",\n",
            "  \"datasets_dir\": \"/content/datasets\",\n",
            "  \"weights_dir\": \"weights\",\n",
            "  \"runs_dir\": \"runs\",\n",
            "  \"uuid\": \"569f3ba64b326db489132663f79cd37279811de477381b83ac131e6cdd129cbb\",\n",
            "  \"sync\": true,\n",
            "  \"api_key\": \"\",\n",
            "  \"openai_api_key\": \"\",\n",
            "  \"clearml\": true,\n",
            "  \"comet\": true,\n",
            "  \"dvc\": true,\n",
            "  \"hub\": true,\n",
            "  \"mlflow\": true,\n",
            "  \"neptune\": true,\n",
            "  \"raytune\": true,\n",
            "  \"tensorboard\": true,\n",
            "  \"wandb\": false,\n",
            "  \"vscode_msg\": true\n",
            "}\n",
            "ðŸ’¡ Learn more about Ultralytics Settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aZV2ndX74MpP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbXfiXqIKfWp"
      },
      "source": [
        "# 2. Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQHpmE0x4euw",
        "outputId": "a6d5fe2c-8ee0-4557-f2b6-b0cd4d327730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# First of all, let's mount Google Drive.\n",
        "# When running this cell, a pop up will appear asking\n",
        "# you to grant access to your Google Drive drive.\n",
        "\n",
        "# This way the training process will be able to store the progress\n",
        "# into your google drive.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WkRayhBF-DTV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO:\n",
        "# Create a folder into your Google Drive.\n",
        "# This folder will be the working directory.\n",
        "# Then point the DRIVE_WORKING_DIR variable to the path of this directory.\n",
        "\n",
        "# In my case is:\n",
        "DRIVE_WORKING_DIR = \"/content/drive/MyDrive/hsicity_rgb_dataset\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoK5pPBZJxqm",
        "outputId": "6d526c64-54f0-4198-bf6d-59cc195a00a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/hsicity_rgb_dataset\n"
          ]
        }
      ],
      "source": [
        "# Let's change the working directory\n",
        "%cd {DRIVE_WORKING_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f8vUZ_DKJtj0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom dataset\n",
        "\n",
        "I've created a Cats and Dogs dataset, as a subset of the MS COCO dataset, exporting only images with dogs and cats.\n",
        "\n",
        "You can [download it from kaggle](https://www.kaggle.com/datasets/estebanuriz/cats-and-dogs-for-object-detection/data).\n",
        "\n",
        "Or you can use your own dataset, the procedure is exactly the same, as long as it is formatted for YOLO.\n"
      ],
      "metadata": {
        "id": "SWQH1wu5ICU_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CqE4-1yQ8zr",
        "outputId": "38ea7de5-3cc0-4160-c029-d60e4bdb7540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '*.zip': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# I've uploaded the zipped dataset file cats_dogs.zip into my Google Drive folder:\n",
        "!ls -lh *.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ux83PSWiKrGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ca7621-de25-45a3-fd5f-5cbff087dc07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open cats_dogs.zip, cats_dogs.zip.zip or cats_dogs.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# decompress the zip to the hard drive instance\n",
        "\n",
        "# NOTE:\n",
        "# for training it is faster to place the files into the Colab instance\n",
        "# hard drive, avoiding network latencies.\n",
        "\n",
        "!unzip -o -qq cats_dogs.zip -d /content/datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOuyz8ENSJPx",
        "outputId": "9d4fc589-687d-4369-ec57-de447ede0c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/datasets/cats_dogs': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# dataset files should be on /content/datasets:\n",
        "\n",
        "!ls /content/datasets/cats_dogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lZuiGzSMAuDZ"
      },
      "outputs": [],
      "source": [
        "# This script prints the dataset structure in a tree-like format.\n",
        "\n",
        "import os\n",
        "\n",
        "def count_files(dir_path, extensions):\n",
        "    return sum(1 for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f)) and os.path.splitext(f)[1].lower() in extensions)\n",
        "\n",
        "\n",
        "def count_image_files(dir_path):\n",
        "    # Define common image extensions\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif'}\n",
        "    return count_files(dir_path, image_extensions)\n",
        "\n",
        "def count_label_files(dir_path):\n",
        "    # Define common label extensions\n",
        "    label_extensions = {'.txt', '.xml'}\n",
        "    return count_files(dir_path, label_extensions)\n",
        "\n",
        "def print_dataset_structure(root_dir, indent=\"\", is_last=True):\n",
        "    \"\"\"\n",
        "      Prints the dataset structure in a tree-like format.\n",
        "\n",
        "      Inputs:\n",
        "        root_dir: str (path where a dataset is placed)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    # Print the root directory\n",
        "    if indent == \"\":\n",
        "        print(root_dir)\n",
        "\n",
        "    # Get sorted directory contents\n",
        "    items = sorted(os.listdir(root_dir))\n",
        "    items_count = len(items)\n",
        "\n",
        "    for i, item in enumerate(items):\n",
        "        item_path = os.path.join(root_dir, item)\n",
        "        is_item_last = (i == items_count - 1)  # Check if the item is the last one\n",
        "\n",
        "        # Determine prefix\n",
        "        prefix = \"â””â”€â”€ \" if is_item_last else \"â”œâ”€â”€ \"\n",
        "        next_indent = indent + (\"    \" if is_item_last else \"â”‚   \")\n",
        "\n",
        "        if item == \".DS_Store\":\n",
        "            pass\n",
        "\n",
        "        elif os.path.isdir(item_path):\n",
        "            # Print directory name\n",
        "            print(f\"{indent}{prefix}{item}\")\n",
        "            # Recurse into subdirectory\n",
        "            subdirs = sorted(os.listdir(item_path))\n",
        "            for j, sub in enumerate(subdirs):\n",
        "                sub_path = os.path.join(item_path, sub)\n",
        "                if os.path.isdir(sub_path):\n",
        "                    img_count = count_image_files(sub_path)\n",
        "                    lbl_count = count_label_files(sub_path)\n",
        "                    sub_prefix = \"â””â”€â”€ \" if j == len(subdirs) - 1 else \"â”œâ”€â”€ \"\n",
        "                    found = []\n",
        "                    if img_count > 0:\n",
        "                        found.append(f\"{img_count} images\")\n",
        "                    if lbl_count > 0:\n",
        "                        found.append(f\"{lbl_count} labels\")\n",
        "                    if len(found) == 0:\n",
        "                      count = \"\"\n",
        "                    else:\n",
        "                      count = \"[\" + \", \".join(found) + \"]\"\n",
        "                    print(f\"{next_indent}{sub_prefix}{sub} {count}\")\n",
        "        else:\n",
        "            print(f\"{indent}{prefix}{item}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_dataset_structure(\"/content/drive/MyDrive/hsicity_proposed_dataet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9TL_4doKhdx",
        "outputId": "50b732bd-d844-488f-b68f-1cc678ae1df4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/hsicity_proposed_dataet\n",
            "â”œâ”€â”€ .ipynb_checkpoints\n",
            "â”œâ”€â”€ dataset.yaml\n",
            "â”œâ”€â”€ images\n",
            "â”‚   â”œâ”€â”€ train [1054 images]\n",
            "â”‚   â””â”€â”€ val [276 images]\n",
            "â”œâ”€â”€ labels\n",
            "â”‚   â”œâ”€â”€ train [1030 labels]\n",
            "â”‚   â”œâ”€â”€ val [276 labels]\n",
            "â”œâ”€â”€ runs\n",
            "â”‚   â””â”€â”€ segment \n",
            "â”œâ”€â”€ yolo11n-seg.pt\n",
            "â””â”€â”€ yolo11n.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1llVUNe8ELRT",
        "outputId": "4781aa23-f138-4230-bfe0-413fda13df13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: /content/drive/MyDrive/hsicity_proposed_dataet/images/train\n",
            "val: /content/drive/MyDrive/hsicity_proposed_dataet/images/val\n",
            "names:\n",
            "  0: road\n",
            "  1: sidewalk\n",
            "  2: building\n",
            "  3: wall\n",
            "  4: fence\n",
            "  5: pole\n",
            "  6: traffic light\n",
            "  7: traffic sign\n",
            "  8: vegetation\n",
            "  9: terrain\n",
            "  10: sky\n",
            "  11: person\n",
            "  12: rider\n",
            "  13: car\n",
            "  14: truck\n",
            "  15: bus\n",
            "  16: train\n",
            "  17: motorcycle\n",
            "  18: bicycle\n"
          ]
        }
      ],
      "source": [
        "# The data.yaml file, defines some dataset parameters, such as\n",
        "# split file paths, and classnames:\n",
        "\n",
        "!cat /content/drive/MyDrive/hsicity_proposed_dataet/dataset.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9JbO6GgZBzJ"
      },
      "source": [
        "##Â Visualizing Some Examples\n",
        "\n",
        "When we work with a dataset it is always convenient to visualize some examples to see what they look like.\n",
        "\n",
        "It is also advisable to check if the labels are correct and are in the format we expect.\n",
        "\n",
        "The following functions allow us to plot some images and their corresponding labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "n0ITqD9ab5RI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gZx3s2_VdZ32"
      },
      "outputs": [],
      "source": [
        "def read_labels(file_name):\n",
        "  \"\"\"\n",
        "    Reads a label file\n",
        "  \"\"\"\n",
        "\n",
        "  with open(file_name, \"r\") as f:\n",
        "    lines = f.read().splitlines()\n",
        "\n",
        "  labels = []\n",
        "  for line in lines:\n",
        "    label = [float(n) for n in line.split(\" \")]\n",
        "    label = int(label[0]), label[1:]\n",
        "    labels.append(label)\n",
        "  return labels\n",
        "\n",
        "\n",
        "def plot(rgb, labels, class_names=['road','sidewalk','building','wall','fence','pole',\n",
        "                                   'traffic light','traffic sign','vegetation','terrain',\n",
        "                                   'sky','person','rider','car','truck','bus','train','motorcycle','bicycle']):\n",
        "  \"\"\"\n",
        "    Given an RGB image and its labels,\n",
        "    plots the image with the bounding boxes.\n",
        "  \"\"\"\n",
        "\n",
        "  plt.figure(figsize=(18, 8))\n",
        "  plt.imshow(rgb)\n",
        "\n",
        "  img_w, img_h = rgb.shape[1], rgb.shape[0]\n",
        "\n",
        "  ax = plt.gca()\n",
        "  for label in labels:\n",
        "    class_id, bbox = label\n",
        "    cx, cy, w, h = bbox\n",
        "\n",
        "    cx = img_w * cx\n",
        "    cy = img_h * cy\n",
        "    w = img_w * w\n",
        "    h = img_h * h\n",
        "\n",
        "    hw = w / 2\n",
        "    hh = h / 2\n",
        "\n",
        "    pt = (cx - hw, cy - hh)\n",
        "\n",
        "    if class_id == 0:\n",
        "      color = 'blue'\n",
        "    else:\n",
        "      color = 'red'\n",
        "\n",
        "    ax.add_patch(Rectangle(\n",
        "        pt, w, h,\n",
        "        edgecolor = color,\n",
        "        fill=None\n",
        "    ))\n",
        "\n",
        "    # Add class label above the bounding box\n",
        "    label_text = class_names[int(class_id)]\n",
        "    label_position = (cx - hw, cy - hh - 5)  # Slightly above the bbox\n",
        "    ax.text(\n",
        "      label_position[0], label_position[1],\n",
        "      label_text,\n",
        "      color=color,\n",
        "      fontsize=12,\n",
        "      fontweight='bold',\n",
        "      bbox=dict(facecolor='white', edgecolor=color, alpha=0.7)\n",
        "    )\n",
        "\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "def sample_some(\n",
        "    data_root,\n",
        "    split=None,\n",
        "    n=10,\n",
        "    seed=1234\n",
        "):\n",
        "  \"\"\"\n",
        "\n",
        "    Randomly samples a specified number of label and corresponding image files from a dataset.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data_root : str.\n",
        "        The root directory of the dataset.\n",
        "    split : str, optional\n",
        "        The split or subfolder within the `labels` directory to sample from. Defaults to `None`,\n",
        "        which matches all subdirectories (i.e., \"**\").\n",
        "    n : int, optional\n",
        "        The number of label files to sample. Defaults to 10.\n",
        "    seed : int, optional\n",
        "        The random seed for reproducibility. Defaults to 1234.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    img_files : list of str\n",
        "        A list of file paths to the corresponding image files in the `images` subdirectory.\n",
        "    lbl_files : list of str\n",
        "        A list of file paths to the sampled label files in the `labels` subdirectory.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  if split is None:\n",
        "    split = \"**\"\n",
        "\n",
        "  pattern = os.path.join(data_root, f\"labels/{split}/*.txt\")\n",
        "  label_files = sorted(glob.glob(pattern))\n",
        "\n",
        "  lbl_files = np.random.choice(label_files, n, replace=False)\n",
        "  lbl_files = list(lbl_files)\n",
        "\n",
        "  img_files = [\n",
        "      f.replace(\"labels\", \"images\").replace(\".txt\", \".png\")\n",
        "      for f in lbl_files\n",
        "  ]\n",
        "\n",
        "  return img_files, lbl_files\n"
      ],
      "metadata": {
        "id": "kiee0iCi990e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_files, lbl_files = sample_some(\n",
        "    data_root=\"/content/drive/MyDrive/hsicity_proposed_dataet\",\n",
        "    split=\"val\",\n",
        "    n=3,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "4Dl3Be_9_Xfy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ5-WkLBBpoc",
        "outputId": "4db9f702-06dd-4af0-a42a-a38f7061ea4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/hsicity_proposed_dataet/images/val/20210409_143420_01.png',\n",
              " '/content/drive/MyDrive/hsicity_proposed_dataet/images/val/20210409_170324_03.png',\n",
              " '/content/drive/MyDrive/hsicity_proposed_dataet/images/val/20210410_113423_02.png']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lbl_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4IWkwwWBtg1",
        "outputId": "de296461-736d-493a-a916-5b4043fde15d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/hsicity_proposed_dataet/labels/val/20210409_143420_01.txt',\n",
              " '/content/drive/MyDrive/hsicity_proposed_dataet/labels/val/20210409_170324_03.txt',\n",
              " '/content/drive/MyDrive/hsicity_proposed_dataet/labels/val/20210410_113423_02.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vUuFouWAcZFj"
      },
      "outputs": [],
      "source": [
        "# choose some random files\n",
        "# data_root = \"/content/drive/MyDrive/hsicity_proposed_dataet\"\n",
        "# samples = sample_some(data_root, split='val')\n",
        "\n",
        "# for image_file, label_file in zip(*samples):\n",
        "#   image = cv2.imread(image_file)\n",
        "#   rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#   labels = read_labels(label_file)\n",
        "\n",
        "#   for label in labels:\n",
        "#     class_id, bbox = label\n",
        "#     print(f\"class_id: {class_id}, bbox: {bbox}\")\n",
        "\n",
        "#   plot(rgb, labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS1lanmGLso_"
      },
      "source": [
        "# 3. Training the model\n",
        "\n",
        "Training the model requires intensive computation provided by GPUs. Theoretically we can train on CPU but it would take a long time. Therefore it is important to have a GPU to train. However, for data preparation and evaluation of results we can use CPU which is much less expensive. Therefore, the recommendation is to use GPU only during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oisip18gM7tB",
        "outputId": "f89a7ec6-7a00-4a43-9495-49431eca4eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available\n",
            "Wed Feb 26 16:59:39 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "if cuda_available:\n",
        "\n",
        "  print(\"CUDA is available\")\n",
        "  !nvidia-smi\n",
        "\n",
        "else:\n",
        "\n",
        "  message = \"\"\"\n",
        "    WARNING: In order to train the model, it is advisable to use GPU.\n",
        "    Change runtime type to GPU from:\n",
        "      menu Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n",
        "      And run all the cells again.\n",
        "  \"\"\"\n",
        "  print(message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej5xQ9_5gJhv",
        "outputId": "e0e78b4e-1dc7-47f1-82f3-f9c8687681ed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/hsicity_proposed_dataet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def serialized_model_file(\n",
        "    checkpoint=\"best\",\n",
        "    use_run=\"train\",\n",
        "):\n",
        "  \"\"\"\n",
        "    Returns the serialized file path.\n",
        "  \"\"\"\n",
        "  return f\"runs/detect/{use_run}/weights/{checkpoint}.pt\"\n"
      ],
      "metadata": {
        "id": "1gG9SrCMiot_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Nmwcl7az0_rL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "def train(\n",
        "    data,\n",
        "    use_run=\"train\",\n",
        "    fallback=\"yolo11n-seg.yaml\",\n",
        "    #fallback=\"yolo11n-seg.pt\",\n",
        "    epochs=100,\n",
        "    augment=True,\n",
        "):\n",
        "\n",
        "  cuda_available = torch.cuda.is_available()\n",
        "  if not cuda_available:\n",
        "    print(\"CUDA is not available, skipping train.\")\n",
        "    return\n",
        "\n",
        "  model_file = serialized_model_file(\"last\", use_run)\n",
        "\n",
        "  if os.path.exists(model_file):\n",
        "    resume_training = True\n",
        "    use_model = model_file\n",
        "  else:\n",
        "    resume_training = False\n",
        "    use_model=fallback\n",
        "\n",
        "\n",
        "  model = YOLO(\n",
        "      use_model\n",
        "  )\n",
        "\n",
        "  model.train(\n",
        "      data=data,\n",
        "      resume=resume_training,\n",
        "      epochs=epochs,\n",
        "      optimizer=\"AdamW\",\n",
        "      lr0=0.0001,\n",
        "      imgsz=320,\n",
        "      batch=64,\n",
        "      augment=augment\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(data=\"/content/drive/MyDrive/hsicity_rgb_dataset/dataset.yaml\", use_run=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USyAriDxhliG",
        "outputId": "0c070a94-9768-4512-a378-2a1c751f4c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.80 ðŸš€ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11n-seg.yaml, data=/content/drive/MyDrive/hsicity_rgb_dataset/dataset.yaml, epochs=100, time=None, patience=100, batch=64, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train6\n",
            "Overriding model.yaml nc=80 with nc=19\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    687145  ultralytics.nn.modules.head.Segment          [19, 32, 64, [64, 128, 256]]  \n",
            "YOLO11n-seg summary: 203 layers, 2,846,313 parameters, 2,846,297 gradients, 10.4 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train6', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/hsicity_rgb_dataset/labels/train.cache... 0 images, 225 backgrounds, 51 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 276/276 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_161609_364053.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_161923_00.jpg: ignoring corrupt image/label: broken data stream when reading image file\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_165524_00.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_165539_403822.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_165539_403822.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170055_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170055_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170138_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170138_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170159_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170159_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170201_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170201_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170243_03.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170243_03.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170253_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170253_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170255_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170255_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170302_03.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170302_03.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170314_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170314_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170324_03.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170324_03.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170335_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170335_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170404_03.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170404_03.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170552_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170552_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170623_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_170623_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_171021_03.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_171021_03.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_180606_168209.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_180606_168209.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_180612_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_180612_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_180615_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_180615_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_180731_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_180731_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_180818_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_180818_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_181356_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210409_181356_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_103917_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_103917_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104158_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104158_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104254_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104254_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104335_03.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104335_03.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104539_03.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104539_03.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104720_03.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104720_03.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104851_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_104851_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105301_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105301_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105356_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105356_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105420_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105420_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105426_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105426_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105434_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105434_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105503_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105503_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105529_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105529_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105533_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105533_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105535_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105535_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105622_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105622_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105625_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105625_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105653_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105653_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105702_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105702_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105711_39379.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105711_39379.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105716_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105716_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105919_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_105919_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_110028_01.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_110028_01.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_110112_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_110112_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_110241_02.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_110241_02.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_110314_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_110314_00.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_110354_00.jpg: ignoring corrupt image/label: cannot identify image file '/content/drive/MyDrive/hsicity_rgb_dataset/images/train/20210410_110354_00.jpg'\n",
            "WARNING âš ï¸ No labels found in /content/drive/MyDrive/hsicity_rgb_dataset/labels/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/hsicity_rgb_dataset/labels/val.cache... 276 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 276/276 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/segment/train6/labels.jpg... \n",
            "zero-size array to reduction operation maximum which has no identity\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train6\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      2.73G          0          0      123.3          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      2.68G          0          0      122.1          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      2.68G          0          0        122          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:10<00:00,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100       2.7G          0          0        106          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100       2.7G          0          0      89.45          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:11<00:00,  3.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100       2.7G          0          0      58.52          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100       2.7G          0          0      41.33          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100       2.7G          0          0      28.84          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100       2.7G          0          0      20.01          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:10<00:00,  3.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100       2.7G          0          0      14.03          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100       2.7G          0          0      10.02          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:10<00:00,  3.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100       2.7G          0          0      7.339          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100       2.7G          0          0      5.492          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:10<00:00,  3.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100       2.7G          0          0      4.228          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100       2.7G          0          0      3.377          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100       2.7G          0          0      2.753          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100       2.7G          0          0      2.259          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100       2.7G          0          0      1.862          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100       2.7G          0          0      1.557          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100       2.7G          0          0      1.357          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100       2.7G          0          0      1.202          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:10<00:00,  3.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100       2.7G          0          0      1.071          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100       2.7G          0          0     0.9563          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:10<00:00,  3.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100       2.7G          0          0     0.8814          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100       2.7G          0          0     0.8345          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100       2.7G          0          0     0.7911          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100       2.7G          0          0     0.7554          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100       2.7G          0          0     0.7268          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100       2.7G          0          0     0.6973          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100       2.7G          0          0     0.6638          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100       2.7G          0          0     0.6227          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:10<00:00,  3.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100       2.7G          0          0     0.5873          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100       2.7G          0          0     0.5615          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100       2.7G          0          0     0.5414          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100       2.7G          0          0     0.5242          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100       2.7G          0          0       0.51          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100       2.7G          0          0     0.4975          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100       2.7G          0          0     0.4862          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100       2.7G          0          0     0.4737          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100       2.7G          0          0      0.464          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100       2.7G          0          0     0.4562          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100       2.7G          0          0     0.4475          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100       2.7G          0          0     0.4387          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100       2.7G          0          0       0.43          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100       2.7G          0          0     0.4192          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100       2.7G          0          0     0.4067          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100       2.7G          0          0      0.397          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100       2.7G          0          0     0.3857          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100       2.7G          0          0     0.3773          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100       2.7G          0          0     0.3703          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100       2.7G          0          0     0.3645          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        276      18647          0          0          0          0          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100       2.7G          0          0     0.3592          0          0        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding():\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "!export LC_ALL=en_US.UTF-8\n",
        "!export LANG=en_US.UTF-8"
      ],
      "metadata": {
        "id": "oDzlXXvzR-ZA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo settings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WasEwJAmdNb5",
        "outputId": "18679f0f-f903-434a-a56c-1f4e1cf764ec"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSONDict(\"/root/.config/Ultralytics/settings.json\"):\n",
            "{\n",
            "  \"settings_version\": \"0.0.6\",\n",
            "  \"datasets_dir\": \"/content/datasets\",\n",
            "  \"weights_dir\": \"weights\",\n",
            "  \"runs_dir\": \"runs\",\n",
            "  \"uuid\": \"569f3ba64b326db489132663f79cd37279811de477381b83ac131e6cdd129cbb\",\n",
            "  \"sync\": true,\n",
            "  \"api_key\": \"\",\n",
            "  \"openai_api_key\": \"\",\n",
            "  \"clearml\": true,\n",
            "  \"comet\": true,\n",
            "  \"dvc\": true,\n",
            "  \"hub\": true,\n",
            "  \"mlflow\": true,\n",
            "  \"neptune\": true,\n",
            "  \"raytune\": true,\n",
            "  \"tensorboard\": true,\n",
            "  \"wandb\": false,\n",
            "  \"vscode_msg\": true\n",
            "}\n",
            "ðŸ’¡ Learn more about Ultralytics Settings at https://docs.ultralytics.com/quickstart/#ultralytics-settings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gNXQSumQgrOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC84Xhb8t5GF"
      },
      "source": [
        "# 4. Reviewing TrainingÂ Results\n",
        "\n",
        "After training we will find some resulting files into the runs directory:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## checking results into the \"runs\" directory\n",
        "\n",
        "Ultralytics package creates the \"runs\" directory, where the results are stored. Since we are training an object detector, the detect/train directory is created:\n",
        "\n",
        "If we train again with different configurations, new directories train2, train3, train4â€¦ will be created, unless we resume training. If we resume training, the corresponding directories are re-used."
      ],
      "metadata": {
        "id": "1WNdroLvIq1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l runs/segment/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etwfCsQPCDYk",
        "outputId": "d87040c8-3790-4e2b-a9a2-9fc0f1d09384"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 6\n",
            "-rw------- 1 root root 1563 Feb 26 16:54 args.yaml\n",
            "drwx------ 2 root root 4096 Feb 26 16:54 weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training history\n",
        "\n",
        "we can observe, a sharp worsening jump in the loss curves, and after that the model starts improving. One possible explanation is as follows: My dataset is a sub-set of COCO, the pre-trained weights at start were created  using the same images, so the model already knew how to detect cats and dogs. Surely I started with a very high learning rate, destroying the previous learned knowledge? Should I start with a much lower learning rate? or perhaps should I freeze the first layers, to avoid this effect and achieve much faster convergence?"
      ],
      "metadata": {
        "id": "CfRr-67KCYTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from PIL import Image\n",
        "\n",
        "Image.open(\"runs/segment/train/results.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "nq8c5B07CPlI",
        "outputId": "82aa146e-68ee-4146-9ec0-50ec1fcadb4a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'runs/segment/train/results.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-f3d756e7b6e5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"runs/segment/train/results.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/segment/train/results.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### args.yaml\n",
        "\n",
        "Into the `args.yaml` file we can check the running arguments, like total number of epochs, enabled augmentations, etc.\n",
        "\n",
        "Check its contents to see which parameters were used for this experiment."
      ],
      "metadata": {
        "id": "x8_u1uwbC14D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat runs/segment/train/args.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jY7-QPxC1YT",
        "outputId": "c4b6d27d-23b7-430b-8933-87e25e5c3311"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "task: segment\n",
            "mode: train\n",
            "model: yolo11n-seg.pt\n",
            "data: /content/datasets/cats_dogs/data.yaml\n",
            "epochs: 100\n",
            "time: null\n",
            "patience: 100\n",
            "batch: 64\n",
            "imgsz: 320\n",
            "save: true\n",
            "save_period: -1\n",
            "cache: false\n",
            "device: null\n",
            "workers: 8\n",
            "project: null\n",
            "name: train\n",
            "exist_ok: false\n",
            "pretrained: true\n",
            "optimizer: AdamW\n",
            "verbose: true\n",
            "seed: 0\n",
            "deterministic: true\n",
            "single_cls: false\n",
            "rect: false\n",
            "cos_lr: false\n",
            "close_mosaic: 10\n",
            "resume: false\n",
            "amp: true\n",
            "fraction: 1.0\n",
            "profile: false\n",
            "freeze: null\n",
            "multi_scale: false\n",
            "overlap_mask: true\n",
            "mask_ratio: 4\n",
            "dropout: 0.0\n",
            "val: true\n",
            "split: val\n",
            "save_json: false\n",
            "save_hybrid: false\n",
            "conf: null\n",
            "iou: 0.7\n",
            "max_det: 300\n",
            "half: false\n",
            "dnn: false\n",
            "plots: true\n",
            "source: null\n",
            "vid_stride: 1\n",
            "stream_buffer: false\n",
            "visualize: false\n",
            "augment: true\n",
            "agnostic_nms: false\n",
            "classes: null\n",
            "retina_masks: false\n",
            "embed: null\n",
            "show: false\n",
            "save_frames: false\n",
            "save_txt: false\n",
            "save_conf: false\n",
            "save_crop: false\n",
            "show_labels: true\n",
            "show_conf: true\n",
            "show_boxes: true\n",
            "line_width: null\n",
            "format: torchscript\n",
            "keras: false\n",
            "optimize: false\n",
            "int8: false\n",
            "dynamic: false\n",
            "simplify: true\n",
            "opset: null\n",
            "workspace: null\n",
            "nms: false\n",
            "lr0: 0.0001\n",
            "lrf: 0.01\n",
            "momentum: 0.937\n",
            "weight_decay: 0.0005\n",
            "warmup_epochs: 3.0\n",
            "warmup_momentum: 0.8\n",
            "warmup_bias_lr: 0.1\n",
            "box: 7.5\n",
            "cls: 0.5\n",
            "dfl: 1.5\n",
            "pose: 12.0\n",
            "kobj: 1.0\n",
            "nbs: 64\n",
            "hsv_h: 0.015\n",
            "hsv_s: 0.7\n",
            "hsv_v: 0.4\n",
            "degrees: 0.0\n",
            "translate: 0.1\n",
            "scale: 0.5\n",
            "shear: 0.0\n",
            "perspective: 0.0\n",
            "flipud: 0.0\n",
            "fliplr: 0.5\n",
            "bgr: 0.0\n",
            "mosaic: 1.0\n",
            "mixup: 0.0\n",
            "copy_paste: 0.0\n",
            "copy_paste_mode: flip\n",
            "auto_augment: randaugment\n",
            "erasing: 0.4\n",
            "crop_fraction: 1.0\n",
            "cfg: null\n",
            "tracker: botsort.yaml\n",
            "save_dir: runs/segment/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checkpoint files\n",
        "\n",
        "On the weights directory we can find the PyTorch serialized checkpoints files:\n",
        "- best.pt\n",
        "- last.pt\n",
        "\n",
        "These files contain the model weights as well as the training state, so that we can continue training from these serialized files. Use last.pt for continue training, and best.pt for production."
      ],
      "metadata": {
        "id": "HIgjxSgXILic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh runs/segment/train/weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USl4qRFoDIHj",
        "outputId": "4d3cdd06-4ae2-475d-ea1f-2e26d8f93379"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch visualizations\n",
        "\n",
        "The files like `train_batch#.jpg` and `val_batch_pred#.jpg` are grids of batch images and its corresponding bounding boxes:"
      ],
      "metadata": {
        "id": "HBasK9oOKEmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training Visualization\n",
        "here is a training batch visualization.\n",
        "Note the applied augmentation transformations like mosaic, flip, and intensities shifts."
      ],
      "metadata": {
        "id": "LFPLMZ1iLUx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Image.open(\"runs/segment/train/train_batch0.jpg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "VbDYBxk7KppH",
        "outputId": "6980cc7d-df30-47c4-a5a2-257c03bd9f30"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'runs/segment/train/train_batch0.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-ffbc521cd8d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"runs/segment/train/train_batch0.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/segment/train/train_batch0.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validation Visualization\n",
        "here is a validation batch visualization. We can see the predicted bounding boxes, each one with its corresponding class and prediction confidence."
      ],
      "metadata": {
        "id": "fOFTsvTCLhKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"runs/segment/train/val_batch0_pred.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "JC_KreurLl8D",
        "outputId": "8dc9d54b-a17c-4ea7-b89e-65be581154a7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'runs/segment/train/val_batch0_pred.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-f198c66cc402>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"runs/segment/train/val_batch0_pred.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/segment/train/val_batch0_pred.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PR_curve.png\n",
        "\n",
        "Precision-Recall plot which helps us evaluate the object detector by showing the trade-off between precision and recall across different thresholds.\n",
        "\n",
        "By analyzing the PR curve, we can choose confidence thresholds that align with the specific goals of your application, such as prioritizing precision (e.g., for safety-critical tasks) or recall (e.g., for exhaustive search tasks).\n"
      ],
      "metadata": {
        "id": "z4SG44bbL2tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"runs/segment/train/PR_curve.png\")"
      ],
      "metadata": {
        "id": "81M0SrAFKwls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### confusion_matrix.png\n",
        "\n",
        "A confusion matrix in object detection is useful for analyzing how well the model distinguishes between object classes (e.g., cat vs. dog) and background, highlighting misclassifications and false positives/negatives at a glance.\n",
        "\n",
        "By analyzing the confusion matrix, you can pinpoint which classes are most problematic, evaluate the balance between precision and recall, and identify areas where the model might need improvement, such as adjusting thresholds, augmenting the dataset, or fine-tuning the training process.\n",
        "\n",
        "In this case, with a simple glance we see that the weakest point of the model is its False Negatives, that is, cases where the model claims that there are cats or dogs, but according to the labels, they are not really there."
      ],
      "metadata": {
        "id": "n1gAr7j6NJkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(\"runs/segment/train/confusion_matrix.png\")"
      ],
      "metadata": {
        "id": "gpFsFbGnNfmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model"
      ],
      "metadata": {
        "id": "M5L-hz0WOuEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "mp9COQHU9iNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting via cli\n"
      ],
      "metadata": {
        "id": "y1faAEKtO6jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !yolo detect predict model=runs/detect/train/weights/best.pt source=/content/datasets/cats_dogs/images/val/000000547502.jpg"
      ],
      "metadata": {
        "id": "qZPL-4YPh4jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "# Image.open(\"runs/segment/predict4/000000547502.jpg\")"
      ],
      "metadata": {
        "id": "cU_qhGrN5oaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â Predicting using Python"
      ],
      "metadata": {
        "id": "6v_JCNyKg4kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the best.pt model"
      ],
      "metadata": {
        "id": "WtpQJoarQMgb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HSyIURDFCfD"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the best model we have so far:\n",
        "model_file = serialized_model_file(\"best\")\n",
        "print(f\"loading checkpoint {model_file}\")\n",
        "model = YOLO(model_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ploting the results using matlab\n",
        "\n",
        "Ultralytics provide tools for plotting the results, but in a real-world application we'll want to use the prediction results programmatically.\n",
        "\n",
        "The following code reads prediction results, its bounding boxes and plots them using matplotlib.\n"
      ],
      "metadata": {
        "id": "O-VmE-E2PvGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "def convert_to_pixel_coords(box, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Convert YOLO format box (cx, cy, w, h) to pixel coordinates.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        box[0] * img_width,  # cx\n",
        "        box[1] * img_height, # cy\n",
        "        box[2] * img_width,  # w\n",
        "        box[3] * img_height  # h\n",
        "    ]\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Calculate Intersection over Union (IoU) for two bounding boxes.\n",
        "    Boxes are in the format (cx, cy, w, h).\n",
        "    \"\"\"\n",
        "    # Convert (cx, cy, w, h) to (x1, y1, x2, y2)\n",
        "    x1_box1, y1_box1 = box1[0] - box1[2] / 2, box1[1] - box1[3] / 2\n",
        "    x2_box1, y2_box1 = box1[0] + box1[2] / 2, box1[1] + box1[3] / 2\n",
        "\n",
        "    x1_box2, y1_box2 = box2[0] - box2[2] / 2, box2[1] - box2[3] / 2\n",
        "    x2_box2, y2_box2 = box2[0] + box2[2] / 2, box2[1] + box2[3] / 2\n",
        "\n",
        "    # Calculate intersection\n",
        "    inter_x1 = max(x1_box1, x1_box2)\n",
        "    inter_y1 = max(y1_box1, y1_box2)\n",
        "    inter_x2 = min(x2_box1, x2_box2)\n",
        "    inter_y2 = min(y2_box1, y2_box2)\n",
        "\n",
        "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
        "\n",
        "    # Calculate union\n",
        "    box1_area = (x2_box1 - x1_box1) * (y2_box1 - y1_box1)\n",
        "    box2_area = (x2_box2 - x1_box2) * (y2_box2 - y1_box2)\n",
        "\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "    return inter_area / union_area if union_area > 0 else 0\n",
        "\n",
        "def plot_result(rgb, result, label=None, iou_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Plot YOLO prediction results and compare with ground truth labels if provided.\n",
        "\n",
        "    Parameters:\n",
        "      - rgb: numpy array of the RGB image.\n",
        "      - result: YOLO prediction result.\n",
        "      - label: Optional ground truth labels [(class_id, [cx, cy, w, h]), ...].\n",
        "      - iou_threshold: IoU threshold to match predictions with ground truth.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(rgb)\n",
        "\n",
        "    class_names = result.names\n",
        "    height, width, _ = rgb.shape\n",
        "\n",
        "    predictions = result.boxes.xywh.cpu().numpy()\n",
        "    pred_classes = result.boxes.cls.cpu().numpy()\n",
        "\n",
        "    gt_used = [False] * len(label) if label else []\n",
        "\n",
        "    for i, pred_box in enumerate(predictions):\n",
        "        pred_class_id = int(pred_classes[i])\n",
        "        pred_box = pred_box.tolist()\n",
        "        matched = False\n",
        "\n",
        "        if label:\n",
        "            for j, (gt_class_id, gt_box) in enumerate(label):\n",
        "                if not gt_used[j] and gt_class_id == pred_class_id:\n",
        "                    # Convert ground truth box to pixel values\n",
        "                    gt_box_pixel = convert_to_pixel_coords(gt_box, width, height)\n",
        "                    iou = calculate_iou(pred_box, gt_box_pixel)\n",
        "                    if iou >= iou_threshold:\n",
        "                        matched = True\n",
        "                        gt_used[j] = True\n",
        "                        break\n",
        "\n",
        "        color = 'green' if matched else 'red'\n",
        "        cx, cy, w, h = pred_box\n",
        "        hw, hh = w / 2, h / 2\n",
        "\n",
        "        ax.add_patch(Rectangle(\n",
        "            (cx - hw, cy - hh), w, h,\n",
        "            edgecolor=color,\n",
        "            fill=None,\n",
        "            linewidth=2\n",
        "        ))\n",
        "\n",
        "        label_text = f\"{class_names[pred_class_id]} ({iou:.2f})\" if matched else class_names[pred_class_id]\n",
        "        ax.text(\n",
        "            cx - hw, cy - hh - 5,\n",
        "            label_text,\n",
        "            color=color,\n",
        "            fontsize=10,\n",
        "            fontweight='bold',\n",
        "            bbox=dict(facecolor='white', edgecolor=color, alpha=0.7)\n",
        "        )\n",
        "\n",
        "    if label:\n",
        "        for gt_class_id, gt_box in label:\n",
        "            # Convert ground truth box to pixel values\n",
        "            gt_box_pixel = convert_to_pixel_coords(gt_box, width, height)\n",
        "            cx, cy, w, h = gt_box_pixel\n",
        "            hw, hh = w / 2, h / 2\n",
        "\n",
        "            ax.add_patch(Rectangle(\n",
        "                (cx - hw, cy - hh), w, h,\n",
        "                edgecolor='blue',\n",
        "                fill=None,\n",
        "                linestyle='--',\n",
        "                linewidth=1\n",
        "            ))\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Bbj0y-FjDDOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbsmIzcpN8kX"
      },
      "outputs": [],
      "source": [
        "samples = sample_some(\n",
        "    data_root=\"/content/datasets/cats_dogs\",\n",
        "    split=\"val\",\n",
        "    seed=42,\n",
        "    n=16\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_file, labels_file in zip(*samples):\n",
        "\n",
        "    img = cv2.imread(image_file)\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    labels = read_labels(labels_file)\n",
        "    result = model.predict(rgb, conf=0.5, iou=0.3)[0]\n",
        "\n",
        "    plot_result(rgb, result, labels)"
      ],
      "metadata": {
        "id": "mwON09wQCMWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4qEq5r-xDS6-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}